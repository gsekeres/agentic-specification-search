paper_id,spec_run_id,spec_id,spec_tree_path,baseline_group_id,outcome_var,treatment_var,coefficient,std_error,p_value,ci_lower,ci_upper,n_obs,r_squared,coefficient_vector_json,sample_desc,fixed_effects,controls_desc,cluster_var,run_success,run_error
180741-V1,G1__baseline__table3_col1,baseline,designs/randomized_experiment.md#baseline,G1,recommendincentive,choicebefore,0.1954691956193849,0.016087449689087076,0.0,0.16392976034919005,0.22700863088957973,4448,0.10578593975453365,"{""coefficients"": {""Intercept"": 0.7365368586926251, ""choicebefore"": 0.1954691956193849, ""choicebeforenoconflict"": -0.13713563826083605, ""noconflict"": 0.2563678576305935, ""incentiveB"": -0.1711751279183773, ""professionalsfree"": -0.026284078594380717, ""seeincentivecostly"": 0.03536065827208622, ""seequalitycostly"": 0.00365342585261141, ""wave2"": -0.017981068694078523, ""wave3"": -0.02752225937932447, ""professionalscloudresearch"": 0.0992939689615797, ""incentiveshigh"": 0.0440927067891834, ""incentiveleft"": 0.006832196631538859, ""incentiveshigh_incentiveleft"": 0.007988420358371441, ""age"": -0.0019075228944599842, ""female"": 0.005227763910635506}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}}",Highx10==0 & Highx100==0 & getyourchoice==1,,choicebeforenoconflict noconflict incentiveB professionalsfree seeincentivecostly seequalitycostly wave2 wave3 professionalscloudresearch incentiveshigh incentiveleft incentiveshigh_incentiveleft age female,,1,
180741-V1,G1__baseline__table3_col2,baseline,designs/randomized_experiment.md#baseline,G1,recommendincentive,choicebefore,0.002991696376976573,0.028848623239888477,0.9174192372422432,-0.053597999128961286,0.059581391882914427,1460,0.08298632481333867,"{""coefficients"": {""Intercept"": 0.8641476362867435, ""choicebefore"": 0.002991696376976573, ""choicebeforenoconflict"": 0.012138880173430512, ""noconflict"": 0.20190313891039985, ""incentiveB"": -0.187485042724119, ""professionalsfree"": 0.050930423019818746, ""seeincentivecostly"": 0.020131747669319335, ""seequalitycostly"": 0.09316045510590318, ""wave2"": 0.0015041512207046885, ""wave3"": -0.07373901019672809, ""professionalscloudresearch"": -0.05791681772324897, ""incentiveshigh"": 0.05980037182650408, ""incentiveleft"": 0.0035846824691146122, ""incentiveshigh_incentiveleft"": 0.004379348328724387, ""age"": -0.002710857142215305, ""female"": -0.014927591533528281}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}}",Highx10==0 & Highx100==0 & getyourchoice==0,,choicebeforenoconflict noconflict incentiveB professionalsfree seeincentivecostly seequalitycostly wave2 wave3 professionalscloudresearch incentiveshigh incentiveleft incentiveshigh_incentiveleft age female,,1,
180741-V1,G1__baseline__table3_col3,baseline,designs/randomized_experiment.md#baseline,G1,recommendincentive,choicebefore,0.18146698310628154,0.01527460283781762,0.0,0.1515231573405086,0.21141080887205446,5908,0.09729082620464347,"{""coefficients"": {""Intercept"": 0.7545598901925088, ""choicebefore"": 0.18146698310628154, ""choicebeforenoconflict"": -0.09809594671076974, ""noconflict"": 0.23643358648295754, ""notgetyourchoice"": 0.060485563915573866, ""choicebeforenotgetyourchoice"": -0.1402179384517546, ""notgetyourchoicenoconflict"": 0.01914505184882021, ""incentiveB"": -0.17540612001557943, ""professionalsfree"": -0.005563726500344341, ""seeincentivecostly"": 0.031226754206084725, ""seequalitycostly"": 0.027452399851566518, ""wave2"": -0.012724162394529793, ""wave3"": -0.04017791430936544, ""professionalscloudresearch"": 0.05687408906116385, ""incentiveshigh"": 0.0486592396033975, ""incentiveleft"": 0.007555562111324277, ""incentiveshigh_incentiveleft"": 0.0050761992613817175, ""age"": -0.0021153022452700173, ""female"": -0.0006736815174099961}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}}",Highx10==0 & Highx100==0,,choicebeforenoconflict noconflict notgetyourchoice choicebeforenotgetyourchoice notgetyourchoicenoconflict incentiveB professionalsfree seeincentivecostly seequalitycostly wave2 wave3 professionalscloudresearch incentiveshigh incentiveleft incentiveshigh_incentiveleft age female,,1,
180741-V1,G2__baseline__tablec1_col1,baseline,designs/randomized_experiment.md#baseline,G2,recommendincentive,seeincentivefirst,0.14162137075152095,0.062496062779004165,0.024480471287961825,0.018410983453297572,0.26483175804974435,213,0.1373871707753842,"{""coefficients"": {""Intercept"": 0.6958219930906865, ""seeincentivefirst"": 0.14162137075152095, ""incentiveB"": -0.19285040191592223, ""female"": 0.0866847579612609, ""age"": -0.0005333186676174444, ""stdalpha"": 0.10837394495704195}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}}",missingalpha==0 & conflict==1,,noconflict incentiveB female age stdalpha,,1,
180741-V1,G2__baseline__tablec1_col2,baseline,designs/randomized_experiment.md#baseline,G2,recommendincentive,seeincentivefirst,0.030255810442664743,0.08078860354309328,0.70901883996599,-0.13051863432267255,0.19103025520800201,86,0.027946670563552045,"{""coefficients"": {""Intercept"": 0.9345319226222156, ""seeincentivefirst"": 0.030255810442664743, ""incentiveB"": -0.06579607020899617, ""female"": -0.055456546960496664, ""age"": -5.9040249358827305e-05, ""stdalpha"": -0.025956770710932893}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}}",missingalpha==0 & conflict==0,,noconflict incentiveB female age stdalpha,,1,
180741-V1,G2__baseline__tablec1_col3,baseline,designs/randomized_experiment.md#baseline,G2,recommendincentive,seeincentivefirst,0.14847529723356845,0.06186265311988571,0.0170197728077075,0.026720344071100702,0.2702302503960362,299,0.12360655099899631,"{""coefficients"": {""Intercept"": 0.6959597535597661, ""seeincentivefirst"": 0.14847529723356845, ""noconflict"": 0.25956156328523644, ""seeincentivefirst_noconflict"": -0.12959039481316736, ""incentiveB"": -0.17490399980458718, ""female"": 0.05311656566635743, ""age"": -0.00043014502513433975, ""stdalpha"": 0.07642559121314506}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}}",missingalpha==0,,noconflict seeincentivefirst_noconflict incentiveB female age stdalpha,,1,
180741-V1,G3__baseline__table2_col1,baseline,designs/randomized_experiment.md#baseline,G3,choicebefore,seeincentivecostly,-0.1393427236905924,0.01779561152246597,5.773159728050814e-15,-0.17422864291406562,-0.10445680446711916,5908,0.03433545326834975,"{""coefficients"": {""Intercept"": 0.6740403911447325, ""seeincentivecostly"": -0.1393427236905924, ""professionalsfree"": -0.0952064189790702, ""seequalitycostly"": 0.1517455748412563, ""wave2"": 0.03604174378995028, ""wave3"": -0.08858839769066618, ""professionalscloudresearch"": 0.03841537946833818, ""incentiveshigh"": -0.06175483619545169, ""incentiveleft"": 0.06353211027440885, ""incentiveshigh_incentiveleft"": -0.006068046517004749, ""age"": -0.002580652069866809, ""female"": -0.029112879531770015}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}}",Highx10==0 & Highx100==0,,seequalitycostly professionalsfree wave2 wave3 professionalscloudresearch incentiveshigh incentiveleft incentiveshigh_incentiveleft age female,,1,
180741-V1,G3__baseline__table2_col2,baseline,designs/randomized_experiment.md#baseline,G3,choicebefore,seeincentivecostly,-0.1395211184214298,0.017761816210167005,4.884981308350689e-15,-0.17434176684749006,-0.10470046999536956,5196,0.03972589664899018,"{""coefficients"": {""Intercept"": 0.6616511363605048, ""seeincentivecostly"": -0.1395211184214298, ""seequalitycostly"": 0.15227284138285227, ""wave2"": 0.03465099817593242, ""wave3"": -0.08983775724511145, ""incentiveshigh"": -0.06097110825893654, ""incentiveleft"": 0.062394195084718676, ""incentiveshigh_incentiveleft"": -0.0051261043240801545, ""age"": -0.002316414282381311, ""female"": -0.023666952045536437, ""stdalpha"": 0.028194872745175566}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}}",Highx10==0 & Highx100==0 & professionals==0,,seequalitycostly professionalsfree stdalpha wave2 wave3 professionalscloudresearch incentiveshigh incentiveleft incentiveshigh_incentiveleft age female,,1,
180741-V1,G3__baseline__table2_col3,baseline,designs/randomized_experiment.md#baseline,G3,choicebefore,seeincentivecostly,-0.13970521836194078,0.017761074594607157,4.440892098500626e-15,-0.17452441604596047,-0.10488602067792108,5196,0.040207659158967846,"{""coefficients"": {""Intercept"": 0.6614629088306896, ""seeincentivecostly"": -0.13970521836194078, ""seequalitycostly"": 0.15196108812559447, ""wave2"": 0.03408445384404431, ""wave3"": -0.08985041512347793, ""incentiveshigh"": -0.06067019410528688, ""incentiveleft"": 0.06206818784829289, ""incentiveshigh_incentiveleft"": -0.005019420792421667, ""age"": -0.0023111682515836026, ""female"": -0.023369099606635288, ""stdalpha"": 0.039165224578517566, ""selfishseeincentivecostly"": -0.022393311483723595, ""selfishseequalitycostly"": -0.02113984520373518}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}}",Highx10==0 & Highx100==0,,seequalitycostly professionalsfree stdalpha selfishseeincentivecostly selfishseequalitycostly wave2 wave3 professionalscloudresearch incentiveshigh incentiveleft incentiveshigh_incentiveleft age female,,1,
180741-V1,G1__design__diff_in_means,design/randomized_experiment/estimator/diff_in_means,designs/randomized_experiment.md#diff-in-means,G1,recommendincentive,choicebefore,0.12246222040070855,0.011358228718306678,0.0,0.10019594339305427,0.14472849740836283,5915,0.019587740861874647,"{""coefficients"": {""Intercept"": 0.6787620064034152, ""choicebefore"": 0.12246222040070855}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}}",Highx10==0 & Highx100==0,,none,,1,
180741-V1,G1__design__with_covariates,design/randomized_experiment/estimator/with_covariates,designs/randomized_experiment.md#with-covariates,G1,recommendincentive,choicebefore,0.18693468190120655,0.015423977296980569,0.0,0.15669804738021162,0.21717131642220147,5915,0.052212081307154934,"{""coefficients"": {""Intercept"": 0.6032695442906283, ""choicebefore"": 0.18693468190120655, ""choicebeforenoconflict"": -0.09834144016030395, ""noconflict"": 0.19824444085106588, ""notgetyourchoice"": 0.06233842067573513, ""choicebeforenotgetyourchoice"": -0.14385743553999017, ""notgetyourchoicenoconflict"": 0.01583789691741667}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}}",Highx10==0 & Highx100==0,,choicebeforenoconflict noconflict notgetyourchoice choicebeforenotgetyourchoice notgetyourchoicenoconflict (structural only),,1,
180741-V1,G2__design__diff_in_means,design/randomized_experiment/estimator/diff_in_means,designs/randomized_experiment.md#diff-in-means,G2,recommendincentive,seeincentivefirst,0.1287146437522379,0.05001243157054481,0.010548067438026276,0.030291002357416247,0.22713828514705955,299,0.02223323215804418,"{""coefficients"": {""Intercept"": 0.6870748299319727, ""seeincentivefirst"": 0.1287146437522379}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}}",missingalpha==0,,none,,1,
180741-V1,G2__design__with_covariates,design/randomized_experiment/estimator/with_covariates,designs/randomized_experiment.md#with-covariates,G2,recommendincentive,seeincentivefirst,0.16798941798941813,0.06263340954744953,0.007728341093518942,0.044724480734513405,0.29125435524432286,299,0.05831284386839952,"{""coefficients"": {""Intercept"": 0.619047619047619, ""seeincentivefirst"": 0.16798941798941813, ""noconflict"": 0.23809523809523828, ""seeincentivefirst_noconflict"": -0.13876863876863896}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}}",missingalpha==0,,noconflict seeincentivefirst_noconflict (structural only),,1,
180741-V1,G3__design__diff_in_means,design/randomized_experiment/estimator/diff_in_means,designs/randomized_experiment.md#diff-in-means,G3,choicebefore,seeincentivecostly,-0.15544535933097492,0.014547880019628633,0.0,-0.1839645179449478,-0.12692620071700203,5915,0.0188296679161033,"{""coefficients"": {""Intercept"": 0.565816678152998, ""seeincentivecostly"": -0.15544535933097492}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}}",Highx10==0 & Highx100==0,,none,,1,
180741-V1,G3__design__with_covariates,design/randomized_experiment/estimator/with_covariates,designs/randomized_experiment.md#with-covariates,G3,choicebefore,seeincentivecostly,-0.13801577795217052,0.015186753892301234,0.0,-0.1677873637433996,-0.10824419216094144,5915,0.021590486759161198,"{""coefficients"": {""Intercept"": 0.5483870967741936, ""seeincentivecostly"": -0.13801577795217052, ""seequalitycostly"": 0.07110681137950842}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}}",Highx10==0 & Highx100==0,,seequalitycostly (structural only),,1,
180741-V1,G1__rc__loo__incentiveB,rc/controls/loo/incentiveB,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.1851676642623219,0.015620612047084119,0.0,0.15454553456546005,0.21578979395918374,5908,0.058895561544829556,"{""coefficients"": {""Intercept"": 0.6788546930882631, ""choicebefore"": 0.1851676642623219, ""choicebeforenoconflict"": -0.09501036168734357, ""noconflict"": 0.19543737090849977, ""notgetyourchoice"": 0.06289428634396421, ""choicebeforenotgetyourchoice"": -0.14401928488908908, ""notgetyourchoicenoconflict"": 0.013324184150927, ""professionalsfree"": -0.0038797061115201197, ""seeincentivecostly"": 0.0325928701026267, ""seequalitycostly"": 0.02618330593680085, ""wave2"": -0.01235492798715234, ""wave3"": -0.038452248464247094, ""professionalscloudresearch"": 0.05577213281155181, ""incentiveshigh"": 0.045372194946444136, ""incentiveleft"": 0.009905791244783082, ""incentiveshigh_incentiveleft"": 0.014796971854172761, ""age"": -0.0022156135531482607, ""female"": 0.0014358747756302035}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/incentiveB"", ""family"": ""loo"", ""dropped"": [""incentiveB""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus incentiveB,,1,
180741-V1,G1__rc__loo__professionalsfree,rc/controls/loo/professionalsfree,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.18162122457359772,0.015252314024704002,0.0,0.15172109410278586,0.21152135504440958,5908,0.09728080522519134,"{""coefficients"": {""Intercept"": 0.752935404062804, ""choicebefore"": 0.18162122457359772, ""choicebeforenoconflict"": -0.09813782987676989, ""noconflict"": 0.236429079840765, ""notgetyourchoice"": 0.060476799022256535, ""choicebeforenotgetyourchoice"": -0.14023956355504197, ""notgetyourchoicenoconflict"": 0.01920692254881064, ""incentiveB"": -0.17539226334729535, ""seeincentivecostly"": 0.03258501769512801, ""seequalitycostly"": 0.028102581968568435, ""wave2"": -0.011281177255492908, ""wave3"": -0.03938907652736321, ""professionalscloudresearch"": 0.05275103574178841, ""incentiveshigh"": 0.04866029358332274, ""incentiveleft"": 0.007539703565085182, ""incentiveshigh_incentiveleft"": 0.005086718579032794, ""age"": -0.0021115979695051504, ""female"": -0.0007574595383441438}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/professionalsfree"", ""family"": ""loo"", ""dropped"": [""professionalsfree""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus professionalsfree,,1,
180741-V1,G1__rc__loo__seeincentivecostly,rc/controls/loo/seeincentivecostly,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.17890711599175824,0.015208310828765706,0.0,0.14909324792660866,0.2087209840569078,5908,0.09663306491338675,"{""coefficients"": {""Intercept"": 0.7725971357373224, ""choicebefore"": 0.17890711599175824, ""choicebeforenoconflict"": -0.0975341803029921, ""noconflict"": 0.23641302862334673, ""notgetyourchoice"": 0.06020304098010595, ""choicebeforenotgetyourchoice"": -0.13997138314408106, ""notgetyourchoicenoconflict"": 0.01923993928757131, ""incentiveB"": -0.175537580760433, ""professionalsfree"": -0.02144850251092765, ""seequalitycostly"": 0.012295474257409546, ""wave2"": -0.02830535689479701, ""wave3"": -0.04050267180856478, ""professionalscloudresearch"": 0.05694913214909865, ""incentiveshigh"": 0.048516311370868655, ""incentiveleft"": 0.007738790689398887, ""incentiveshigh_incentiveleft"": 0.005017414350339136, ""age"": -0.0021371512378517174, ""female"": -0.0008981070376914157}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/seeincentivecostly"", ""family"": ""loo"", ""dropped"": [""seeincentivecostly""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus seeincentivecostly,,1,
180741-V1,G1__rc__loo__seequalitycostly,rc/controls/loo/seequalitycostly,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.1823287806753859,0.015269624734402168,0.0,0.1523947148635052,0.21226284648726662,5908,0.09710667420148966,"{""coefficients"": {""Intercept"": 0.7569535104512005, ""choicebefore"": 0.1823287806753859, ""choicebeforenoconflict"": -0.09795947387992629, ""noconflict"": 0.23638518758608934, ""notgetyourchoice"": 0.06026854261409825, ""choicebeforenotgetyourchoice"": -0.14060052645872775, ""notgetyourchoicenoconflict"": 0.01963837197624199, ""incentiveB"": -0.17536722831176205, ""professionalsfree"": -0.007985239211092104, ""seeincentivecostly"": 0.026399882198512668, ""wave2"": -0.015248761232127895, ""wave3"": -0.022365256453902825, ""professionalscloudresearch"": 0.05680147543733344, ""incentiveshigh"": 0.04868534232102451, ""incentiveleft"": 0.00749113215061886, ""incentiveshigh_incentiveleft"": 0.005098065146484885, ""age"": -0.0021225443968504215, ""female"": -0.0007881033718510768}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/seequalitycostly"", ""family"": ""loo"", ""dropped"": [""seequalitycostly""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus seequalitycostly,,1,
180741-V1,G1__rc__loo__wave2,rc/controls/loo/wave2,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.18144817795322757,0.015270920813080938,0.0,0.15151157135169796,0.21138478455475718,5908,0.09725945900068622,"{""coefficients"": {""Intercept"": 0.7525845078744914, ""choicebefore"": 0.18144817795322757, ""choicebeforenoconflict"": -0.09822553752949396, ""noconflict"": 0.23643556357462073, ""notgetyourchoice"": 0.06041727709416097, ""choicebeforenotgetyourchoice"": -0.1402697942283266, ""notgetyourchoicenoconflict"": 0.019138592916843222, ""incentiveB"": -0.17540196171531947, ""professionalsfree"": -0.0035887403050537327, ""seeincentivecostly"": 0.03305025470433831, ""seequalitycostly"": 0.02838017524736953, ""wave3"": -0.039124880381576584, ""professionalscloudresearch"": 0.05687063373748772, ""incentiveshigh"": 0.03790968041640343, ""incentiveleft"": -0.003190638550300701, ""incentiveshigh_incentiveleft"": 0.015824503170706855, ""age"": -0.0021135929078940933, ""female"": -0.0006969212908617608}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/wave2"", ""family"": ""loo"", ""dropped"": [""wave2""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus wave2,,1,
180741-V1,G1__rc__loo__wave3,rc/controls/loo/wave3,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.18254053925905925,0.015266840571959851,0.0,0.1526119314268754,0.2124691470912431,5908,0.09676793080252633,"{""coefficients"": {""Intercept"": 0.7499492597854021, ""choicebefore"": 0.18254053925905925, ""choicebeforenoconflict"": -0.0980901757878645, ""noconflict"": 0.23649166172082392, ""notgetyourchoice"": 0.060369177207242, ""choicebeforenotgetyourchoice"": -0.14086069904689447, ""notgetyourchoicenoconflict"": 0.01954949626829502, ""incentiveB"": -0.17530351910505765, ""professionalsfree"": 0.00013621947643435264, ""seeincentivecostly"": 0.031427406974522544, ""seequalitycostly"": -0.0071065096115138626, ""wave2"": -0.007164822923471945, ""professionalscloudresearch"": 0.0566618341366343, ""incentiveshigh"": 0.04866242456271223, ""incentiveleft"": 0.007492798513677187, ""incentiveshigh_incentiveleft"": 0.005062587160381756, ""age"": -0.0021430679368700098, ""female"": -0.001643497750734679}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/wave3"", ""family"": ""loo"", ""dropped"": [""wave3""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus wave3,,1,
180741-V1,G1__rc__loo__professionalscloudresearch,rc/controls/loo/professionalscloudresearch,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.18179289252203598,0.015272412315548071,0.0,0.1518533620285453,0.21173242301552667,5908,0.09686153321422131,"{""coefficients"": {""Intercept"": 0.754638970534858, ""choicebefore"": 0.18179289252203598, ""choicebeforenoconflict"": -0.09828265185329478, ""noconflict"": 0.2361410355324017, ""notgetyourchoice"": 0.06001694979793629, ""choicebeforenotgetyourchoice"": -0.14036749468398874, ""notgetyourchoicenoconflict"": 0.020880701566462323, ""incentiveB"": -0.17536812113766068, ""professionalsfree"": 0.011715086163135692, ""seeincentivecostly"": 0.031253645306400964, ""seequalitycostly"": 0.027370692464350168, ""wave2"": -0.012713582496670062, ""wave3"": -0.04005481101257121, ""incentiveshigh"": 0.0486064617730436, ""incentiveleft"": 0.007500489185183341, ""incentiveshigh_incentiveleft"": 0.0051050730700357245, ""age"": -0.0021043925252590156, ""female"": -0.0017375982432695713}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/professionalscloudresearch"", ""family"": ""loo"", ""dropped"": [""professionalscloudresearch""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus professionalscloudresearch,,1,
180741-V1,G1__rc__loo__incentiveshigh,rc/controls/loo/incentiveshigh,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.18126324085917384,0.01527037657347518,0.0,0.15132770116691407,0.2111987805514336,5908,0.09700973748911157,"{""coefficients"": {""Intercept"": 0.7546411918977449, ""choicebefore"": 0.18126324085917384, ""choicebeforenoconflict"": -0.0981832856596024, ""noconflict"": 0.2364926375830468, ""notgetyourchoice"": 0.06016360309062338, ""choicebeforenotgetyourchoice"": -0.14042768523025334, ""notgetyourchoicenoconflict"": 0.01925719442643572, ""incentiveB"": -0.1753193737527248, ""professionalsfree"": -0.005567106884311836, ""seeincentivecostly"": 0.031187557041811496, ""seequalitycostly"": 0.027474878370181203, ""wave2"": 0.012465488214478496, ""wave3"": -0.04017932800054092, ""professionalscloudresearch"": 0.056833697533205024, ""incentiveleft"": -0.017625548110652707, ""incentiveshigh_incentiveleft"": 0.05373039925877862, ""age"": -0.0021099055888249155, ""female"": -0.0008925164949169007}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/incentiveshigh"", ""family"": ""loo"", ""dropped"": [""incentiveshigh""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus incentiveshigh,,1,
180741-V1,G1__rc__loo__incentiveleft,rc/controls/loo/incentiveleft,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.1815539272323653,0.01525473808742613,0.0,0.15164904470940294,0.21145880975532766,5908,0.09728437387836664,"{""coefficients"": {""Intercept"": 0.7544813090757124, ""choicebefore"": 0.1815539272323653, ""choicebeforenoconflict"": -0.09814791720121246, ""noconflict"": 0.23643410376932475, ""notgetyourchoice"": 0.06048394134932627, ""choicebeforenotgetyourchoice"": -0.14033312004037982, ""notgetyourchoicenoconflict"": 0.019167501420397717, ""incentiveB"": -0.17541528911796608, ""professionalsfree"": -0.005556207354399818, ""seeincentivecostly"": 0.031234182708765393, ""seequalitycostly"": 0.027444197445316253, ""wave2"": -0.009001463747013801, ""wave3"": -0.04017379589599604, ""professionalscloudresearch"": 0.05686785819606337, ""incentiveshigh"": 0.04493664004678285, ""incentiveshigh_incentiveleft"": 0.012630063552205887, ""age"": -0.0021136737912101273, ""female"": -0.0006814490932794156}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/incentiveleft"", ""family"": ""loo"", ""dropped"": [""incentiveleft""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus incentiveleft,,1,
180741-V1,G1__rc__loo__incentiveshigh_incentiveleft,rc/controls/loo/incentiveshigh_incentiveleft,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.18145032480022147,0.015265851403745593,0.0,0.1515236561005926,0.21137699349985034,5908,0.09728932837933713,"{""coefficients"": {""Intercept"": 0.7546086593899828, ""choicebefore"": 0.18145032480022147, ""choicebeforenoconflict"": -0.09809243994368748, ""noconflict"": 0.23642471989269717, ""notgetyourchoice"": 0.06047604875830333, ""choicebeforenotgetyourchoice"": -0.14016161879326153, ""notgetyourchoicenoconflict"": 0.01915110740067036, ""incentiveB"": -0.17541922360757936, ""professionalsfree"": -0.005565449819333138, ""seeincentivecostly"": 0.031225930737755855, ""seequalitycostly"": 0.02745336167074487, ""wave2"": -0.014010680301063106, ""wave3"": -0.040177605692092055, ""professionalscloudresearch"": 0.05687521778379523, ""incentiveshigh"": 0.05114445906159763, ""incentiveleft"": 0.010165571924674403, ""age"": -0.0021162830141594007, ""female"": -0.0006730198796075115}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/incentiveshigh_incentiveleft"", ""family"": ""loo"", ""dropped"": [""incentiveshigh_incentiveleft""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus incentiveshigh_incentiveleft,,1,
180741-V1,G1__rc__loo__age,rc/controls/loo/age,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.186234248901031,0.015227482992211258,0.0,0.15638280364578666,0.21608569415627532,5915,0.0938579174418489,"{""coefficients"": {""Intercept"": 0.6732500535618602, ""choicebefore"": 0.186234248901031, ""choicebeforenoconflict"": -0.10157372145148354, ""noconflict"": 0.2394520940306343, ""notgetyourchoice"": 0.061113385604193896, ""choicebeforenotgetyourchoice"": -0.14024324700011548, ""notgetyourchoicenoconflict"": 0.020025567125713753, ""incentiveB"": -0.1755762995390742, ""professionalsfree"": -0.002404206936546287, ""seeincentivecostly"": 0.03300084125961315, ""seequalitycostly"": 0.030880852532966758, ""wave2"": -0.01186867015872981, ""wave3"": -0.04538615458553298, ""professionalscloudresearch"": 0.05440279707303878, ""incentiveshigh"": 0.04715128864540458, ""incentiveleft"": 0.004457226546648919, ""incentiveshigh_incentiveleft"": 0.007518509904280399, ""female"": -0.003521063163440606}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/age"", ""family"": ""loo"", ""dropped"": [""age""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus age,,1,
180741-V1,G1__rc__loo__female,rc/controls/loo/female,modules/robustness/controls.md#leave-one-out-controls-loo,G1,recommendincentive,choicebefore,0.18148611529901432,0.015266740631961442,0.0,0.1515577033858882,0.21141452721214044,5908,0.09729024459414903,"{""coefficients"": {""Intercept"": 0.7542398068223626, ""choicebefore"": 0.18148611529901432, ""choicebeforenoconflict"": -0.09811507013636125, ""noconflict"": 0.23643794071204735, ""notgetyourchoice"": 0.0604869788140826, ""choicebeforenotgetyourchoice"": -0.14019094598422613, ""notgetyourchoicenoconflict"": 0.01912946406978178, ""incentiveB"": -0.17539779977666647, ""professionalsfree"": -0.005603883688909545, ""seeincentivecostly"": 0.03123595252314024, ""seequalitycostly"": 0.02746712604335592, ""wave2"": -0.012732301241582712, ""wave3"": -0.040242248170320925, ""professionalscloudresearch"": 0.05699577654035068, ""incentiveshigh"": 0.04869194476107934, ""incentiveleft"": 0.007563414712944385, ""incentiveshigh_incentiveleft"": 0.005074263394856361, ""age"": -0.0021166532426991134}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/loo/female"", ""family"": ""loo"", ""dropped"": [""female""], ""n_controls"": 16}}",Highx10==0 & Highx100==0,,Table3-Col3 minus female,,1,
180741-V1,G1__rc__add__stdalpha,rc/controls/add/stdalpha,modules/robustness/controls.md#add-controls,G1,recommendincentive,choicebefore,0.1663179429578834,0.016347891706447185,0.0,0.13426917257527834,0.19836671334048847,5196,0.10440342969447503,"{""coefficients"": {""Intercept"": 0.7469600092143148, ""choicebefore"": 0.1663179429578834, ""choicebeforenoconflict"": -0.09913982935434312, ""noconflict"": 0.2423671019300363, ""notgetyourchoice"": 0.054785993153235464, ""choicebeforenotgetyourchoice"": -0.1320961093686397, ""notgetyourchoicenoconflict"": 0.020029762745227192, ""incentiveB"": -0.1608953019601605, ""seeincentivecostly"": 0.028746578313341563, ""seequalitycostly"": 0.029693368569277633, ""wave2"": -0.014888485613034502, ""wave3"": -0.04190456565374825, ""incentiveshigh"": 0.04845785620850429, ""incentiveleft"": 0.007221598022172711, ""incentiveshigh_incentiveleft"": 0.006904434587404559, ""age"": -0.0018709068659877792, ""female"": -0.002416416298519316, ""stdalpha"": 0.0494848001553406}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/add/stdalpha"", ""family"": ""add"", ""added"": [""stdalpha""], ""n_controls"": 18}}",Highx10==0 & Highx100==0,,Table3-Col3 plus stdalpha,,1,
180741-V1,G1__rc__add__selfishseeincentivecostly,rc/controls/add/selfishseeincentivecostly,modules/robustness/controls.md#add-controls,G1,recommendincentive,choicebefore,0.17079334989699085,0.01642623570189624,0.0,0.13859099220379623,0.20299570759018548,5196,0.09570511873906984,"{""coefficients"": {""Intercept"": 0.7542548859225566, ""choicebefore"": 0.17079334989699085, ""choicebeforenoconflict"": -0.09839726481762226, ""noconflict"": 0.24009142348428353, ""notgetyourchoice"": 0.05216928853218639, ""choicebeforenotgetyourchoice"": -0.1320851789996737, ""notgetyourchoicenoconflict"": 0.020891781000837824, ""incentiveB"": -0.16247921101232782, ""seeincentivecostly"": 0.030024408378539844, ""seequalitycostly"": 0.02866538618256989, ""wave2"": -0.012416244100903088, ""wave3"": -0.04065274400759203, ""incentiveshigh"": 0.04733428451665819, ""incentiveleft"": 0.008384119868976487, ""incentiveshigh_incentiveleft"": 0.006012784242236386, ""age"": -0.002055289849918058, ""female"": -0.005625813279811375, ""selfishseeincentivecostly"": 0.05032632173329454}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/add/selfishseeincentivecostly"", ""family"": ""add"", ""added"": [""selfishseeincentivecostly""], ""n_controls"": 18}}",Highx10==0 & Highx100==0,,Table3-Col3 plus selfishseeincentivecostly,,1,
180741-V1,G1__rc__add__selfishseequalitycostly,rc/controls/add/selfishseequalitycostly,modules/robustness/controls.md#add-controls,G1,recommendincentive,choicebefore,0.17242909417028607,0.016454813481884267,0.0,0.1401707119618006,0.20468747637877155,5196,0.09303027522360585,"{""coefficients"": {""Intercept"": 0.754641202509259, ""choicebefore"": 0.17242909417028607, ""choicebeforenoconflict"": -0.09972759615976552, ""noconflict"": 0.241789026493787, ""notgetyourchoice"": 0.05455659941855258, ""choicebeforenotgetyourchoice"": -0.13504765729230167, ""notgetyourchoicenoconflict"": 0.02018787495367092, ""incentiveB"": -0.16330527755357932, ""seeincentivecostly"": 0.029992564158865306, ""seequalitycostly"": 0.02877473379255446, ""wave2"": -0.012409096732807335, ""wave3"": -0.040176001828296413, ""incentiveshigh"": 0.047337297326059874, ""incentiveleft"": 0.00829404557737612, ""incentiveshigh_incentiveleft"": 0.00603706425756647, ""age"": -0.0020701631925181406, ""female"": -0.007102064560526566, ""selfishseequalitycostly"": 0.03523739673794835}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""controls"": {""spec_id"": ""rc/controls/add/selfishseequalitycostly"", ""family"": ""add"", ""added"": [""selfishseequalitycostly""], ""n_controls"": 18}}",Highx10==0 & Highx100==0,,Table3-Col3 plus selfishseequalitycostly,,1,
180741-V1,G1__rc__sample__include_inattentive,rc/sample/include_inattentive,modules/robustness/sample.md#include-inattentive,G1,recommendincentive,choicebefore,0.16655888050292508,0.014732263913813413,0.0,0.13767881914946895,0.19543894185638122,6547,0.08924156719208798,"{""coefficients"": {""Intercept"": 0.7551579878404419, ""choicebefore"": 0.16655888050292508, ""choicebeforenoconflict"": -0.09206759315574962, ""noconflict"": 0.23373836933179296, ""notgetyourchoice"": 0.05144297006697099, ""choicebeforenotgetyourchoice"": -0.12799385227431861, ""notgetyourchoicenoconflict"": 0.01931107159918805, ""incentiveB"": -0.1725281477728495, ""professionalsfree"": -0.003122655556369876, ""seeincentivecostly"": 0.02323144644995171, ""seequalitycostly"": 0.020651931455364387, ""wave2"": -0.014739789592268007, ""wave3"": -0.03743214460927588, ""professionalscloudresearch"": 0.05755007356635629, ""incentiveshigh"": 0.005561067320259789, ""incentiveleft"": 0.01277116326931975, ""incentiveshigh_incentiveleft"": 0.04603795010201394, ""age"": -0.00204980080438246, ""female"": 0.0008404289103945369}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""sample"": {""spec_id"": ""rc/sample/include_inattentive"", ""description"": ""Include inattentive participants (those with alphavaluefinal==.)""}}","Highx10==0 & Highx100==0, including inattentive",,Table3-Col3 controls,,1,
180741-V1,G1__rc__sample__include_high_stakes_10x,rc/sample/include_high_stakes_10x,modules/robustness/sample.md#include-subgroup,G1,recommendincentive,choicebefore,0.1845167933700666,0.014872267965121564,0.0,0.15536195895800048,0.21367162778213272,6183,0.09706504385348591,"{""coefficients"": {""Intercept"": 0.7656367837354736, ""choicebefore"": 0.1845167933700666, ""choicebeforenoconflict"": -0.09725652489828919, ""noconflict"": 0.23455345665693125, ""notgetyourchoice"": 0.05887600738689324, ""choicebeforenotgetyourchoice"": -0.14304289962522787, ""notgetyourchoicenoconflict"": 0.02308191390040466, ""incentiveB"": -0.17212673699064454, ""professionalsfree"": -0.012555457164376622, ""seeincentivecostly"": 0.016970380849001328, ""seequalitycostly"": -0.032808533781267635, ""wave2"": -0.02012913767904275, ""wave3"": 0.012869409521633185, ""professionalscloudresearch"": 0.056000807114746844, ""incentiveshigh"": 0.04852002156783889, ""incentiveleft"": 0.007358004477293875, ""incentiveshigh_incentiveleft"": 0.00520686269831172, ""age"": -0.0022283694611794774, ""female"": -0.004229443849946845}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""sample"": {""spec_id"": ""rc/sample/include_high_stakes_10x"", ""description"": ""Include 10x high-stakes participants""}}",Highx100==0 (includes 10x stakes),,Table3-Col3 controls,,1,
180741-V1,G1__rc__sample__include_high_stakes_100x,rc/sample/include_high_stakes_100x,modules/robustness/sample.md#include-subgroup,G1,recommendincentive,choicebefore,0.1860214661388209,0.014712727942624,0.0,0.1571794851509454,0.2148634471266964,6293,0.09622481390147086,"{""coefficients"": {""Intercept"": 0.7625045669775009, ""choicebefore"": 0.1860214661388209, ""choicebeforenoconflict"": -0.09733713454759156, ""noconflict"": 0.23167554705735546, ""notgetyourchoice"": 0.060246777454126016, ""choicebeforenotgetyourchoice"": -0.15091662727798535, ""notgetyourchoicenoconflict"": 0.024980223771031054, ""incentiveB"": -0.17167808705645057, ""professionalsfree"": -0.012820856189400879, ""seeincentivecostly"": 0.015959076418281693, ""seequalitycostly"": -0.037097919624562076, ""wave2"": -0.02035919524025666, ""wave3"": 0.01661447164460703, ""professionalscloudresearch"": 0.05554571308167568, ""incentiveshigh"": 0.04812458737475495, ""incentiveleft"": 0.00672842195558895, ""incentiveshigh_incentiveleft"": 0.005994677654438027, ""age"": -0.002100680631465856, ""female"": -0.0056722005788815396}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""sample"": {""spec_id"": ""rc/sample/include_high_stakes_100x"", ""description"": ""Include all high-stakes participants (10x and 100x)""}}",All stakes included,,Table3-Col3 controls,,1,
180741-V1,G1__rc__sample__restrict_choicefree_only,rc/sample/restrict_choicefree_only,modules/robustness/sample.md#restrict-subgroup,G1,recommendincentive,choicebefore,0.22760955579778516,0.020345263103445168,0.0,0.18771880318832393,0.26750030840724637,3285,0.11032463992128483,"{""coefficients"": {""Intercept"": 0.7391783887226484, ""choicebefore"": 0.22760955579778516, ""choicebeforenoconflict"": -0.12513298123245567, ""noconflict"": 0.23886177712535342, ""notgetyourchoice"": 0.08407525645253752, ""choicebeforenotgetyourchoice"": -0.1646072341486667, ""notgetyourchoicenoconflict"": -0.0028114160453041304, ""incentiveB"": -0.17823980070671502, ""wave2"": -0.012695413632525281, ""wave3"": -0.03984387205894089, ""professionalscloudresearch"": 0.055723025082373076, ""incentiveshigh"": 0.05169989734301899, ""incentiveleft"": 0.004749626800852158, ""incentiveshigh_incentiveleft"": 0.004497352144155877, ""age"": -0.0024544278991064723, ""female"": 0.010122204301779115}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""sample"": {""spec_id"": ""rc/sample/restrict_choicefree_only"", ""description"": ""Restrict to ChoiceFree conditions only""}}",Highx10==0 & Highx100==0 & ChoiceFree only,,Col3 controls minus seeincentivecostly seequalitycostly professionalsfree (collinear in ChoiceFree only),,1,
180741-V1,G1__rc__sample__restrict_professionals_only,rc/sample/restrict_professionals_only,modules/robustness/sample.md#restrict-subgroup,G1,recommendincentive,choicebefore,0.2493840562235709,0.04074478813721424,1.5495968952450312e-09,0.16938781623763843,0.3293802962095034,712,0.15619819319640904,"{""coefficients"": {""Intercept"": 0.7561911267791102, ""choicebefore"": 0.2493840562235709, ""choicebeforenoconflict"": -0.1058974319964859, ""noconflict"": 0.20670479969242994, ""notgetyourchoice"": 0.09546935692284961, ""choicebeforenotgetyourchoice"": -0.1767917955059757, ""notgetyourchoicenoconflict"": 0.04059297978791721, ""incentiveB"": -0.26096912127308475, ""age"": -0.0019842136817722323, ""female"": 0.03515929530346466}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""sample"": {""spec_id"": ""rc/sample/restrict_professionals_only"", ""description"": ""Restrict to professionals only""}}",Highx10==0 & Highx100==0 & professionals==1,,Col3 controls (professionals-only sample),,1,
180741-V1,G1__rc__sample__restrict_incentiveA_only,rc/sample/restrict_incentiveA_only,modules/robustness/sample.md#restrict-subgroup,G1,recommendincentive,choicebefore,0.17215220625136263,0.019000981119007863,0.0,0.13489567641310585,0.2094087360896194,2967,0.06501398294546423,"{""coefficients"": {""Intercept"": 0.7303738807004326, ""choicebefore"": 0.17215220625136263, ""choicebeforenoconflict"": -0.07668306724205698, ""noconflict"": 0.18234536803360973, ""notgetyourchoice"": 0.0726469054279519, ""choicebeforenotgetyourchoice"": -0.16081006698538303, ""notgetyourchoicenoconflict"": 0.04839565400807255, ""professionalsfree"": 0.04086063290614078, ""seeincentivecostly"": 0.026641884430598693, ""seequalitycostly"": -0.001778290422131821, ""wave2"": -0.01356447379078473, ""wave3"": -0.005568612664626366, ""professionalscloudresearch"": 0.08411557368747301, ""incentiveshigh"": -0.011050435715063069, ""incentiveleft"": 0.03929116686402374, ""incentiveshigh_incentiveleft"": 0.033209930203953304, ""age"": -0.0015515148960849985, ""female"": 0.012622704042711649}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""sample"": {""spec_id"": ""rc/sample/restrict_incentiveA_only"", ""description"": ""Restrict to incentiveA observations""}}",Highx10==0 & Highx100==0 & incentiveA==1,,Col3 controls minus incentiveB (collinear),,1,
180741-V1,G1__rc__sample__restrict_incentiveB_only,rc/sample/restrict_incentiveB_only,modules/robustness/sample.md#restrict-subgroup,G1,recommendincentive,choicebefore,0.19711270475414935,0.025083000076080508,5.551115123125783e-15,0.14793056263441606,0.24629484687388264,2941,0.08755954131317767,"{""coefficients"": {""Intercept"": 0.5985061645474827, ""choicebefore"": 0.19711270475414935, ""choicebeforenoconflict"": -0.11959569829674029, ""noconflict"": 0.27530484195887484, ""notgetyourchoice"": 0.04657384378587559, ""choicebeforenotgetyourchoice"": -0.12206811447023429, ""notgetyourchoicenoconflict"": 0.007870212182815034, ""professionalsfree"": -0.05483528465984579, ""seeincentivecostly"": 0.03542419103824424, ""seequalitycostly"": 0.05483123820495486, ""wave2"": -0.013351251095814975, ""wave3"": -0.07401662091130344, ""professionalscloudresearch"": 0.03503526675849586, ""incentiveshigh"": 0.10317374239589691, ""incentiveleft"": -0.026036016680079405, ""incentiveshigh_incentiveleft"": -0.017175462884707247, ""age"": -0.0026516317865740028, ""female"": -0.015138450175378954}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""sample"": {""spec_id"": ""rc/sample/restrict_incentiveB_only"", ""description"": ""Restrict to incentiveB observations""}}",Highx10==0 & Highx100==0 & incentiveB==1,,Col3 controls minus incentiveB (collinear),,1,
180741-V1,G1__rc__outcome__probit,rc/outcome/probit,modules/robustness/functional_form.md#probit,G1,recommendincentive,choicebefore,0.5688844743038854,0.048105288840920406,2.870864312781727e-32,0.4745998407097849,0.663169107897986,5908,0.08923340071464259,"{""coefficients"": {""Intercept"": 0.7813388086168471, ""choicebefore"": 0.5688844743038854, ""choicebeforenoconflict"": -0.22341586961803947, ""noconflict"": 0.7611973650632272, ""notgetyourchoice"": 0.18832557166759767, ""choicebeforenotgetyourchoice"": -0.47799218369048324, ""notgetyourchoicenoconflict"": 0.07389870258495967, ""incentiveB"": -0.5922466636678003, ""professionalsfree"": -0.02120072480874215, ""seeincentivecostly"": 0.10226942755720643, ""seequalitycostly"": 0.07425755084747976, ""wave2"": -0.0646445906303685, ""wave3"": -0.12245105839286592, ""professionalscloudresearch"": 0.21666123497698192, ""incentiveshigh"": 0.19488154213299844, ""incentiveleft"": 0.04645402467308571, ""incentiveshigh_incentiveleft"": -0.018062889995772966, ""age"": -0.0071350677819107386, ""female"": -0.004403719456149314}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""functional_form"": {""spec_id"": ""rc/outcome/probit"", ""model"": ""probit"", ""interpretation"": ""Probit coefficients (not marginal effects); sign and significance comparable to LPM""}}",Highx10==0 & Highx100==0,,Table3-Col3 controls,,1,
180741-V1,G1__rc__outcome__logit,rc/outcome/logit,modules/robustness/functional_form.md#logit,G1,recommendincentive,choicebefore,0.9545891860299869,0.0817807996781261,1.7609798854368467e-31,0.7943017640339749,1.1148766080259989,5908,0.08876668548086242,"{""coefficients"": {""Intercept"": 1.2938208148635488, ""choicebefore"": 0.9545891860299869, ""choicebeforenoconflict"": -0.34689032039072615, ""noconflict"": 1.2882891711258309, ""notgetyourchoice"": 0.3176205083738951, ""choicebeforenotgetyourchoice"": -0.8127854793443423, ""notgetyourchoicenoconflict"": 0.11471573814065968, ""incentiveB"": -0.9991320286119347, ""professionalsfree"": -0.04007900537503736, ""seeincentivecostly"": 0.1775670614404847, ""seequalitycostly"": 0.13756877315495947, ""wave2"": -0.08689273426028031, ""wave3"": -0.2189933056620781, ""professionalscloudresearch"": 0.35650696648660624, ""incentiveshigh"": 0.3093017450922707, ""incentiveleft"": 0.05473726780694154, ""incentiveshigh_incentiveleft"": 0.017543314297030658, ""age"": -0.011926909946584468, ""female"": -0.0048670185207856775}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""In Choice experiments, advisors first state preference for information order (choicebefore), then are randomly assigned to see incentive first (getbefore=1) or quality first (getbefore=0). In NoChoice, assignment is purely random (seeincentivefirst)."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes), attentive participants (alphavaluefinal!=.)""}}, ""functional_form"": {""spec_id"": ""rc/outcome/logit"", ""model"": ""logit"", ""interpretation"": ""Logit coefficients (not marginal effects); sign and significance comparable to LPM""}}",Highx10==0 & Highx100==0,,Table3-Col3 controls,,1,
180741-V1,G2__rc__loo__incentiveB,rc/controls/loo/incentiveB,modules/robustness/controls.md#leave-one-out-controls-loo,G2,recommendincentive,seeincentivefirst,0.14950384057939078,0.0631984466832257,0.018652935329920517,0.02512162477240025,0.2738860563863813,299,0.08507363456621697,"{""coefficients"": {""Intercept"": 0.629651570971973, ""seeincentivefirst"": 0.14950384057939078, ""noconflict"": 0.21782214941483663, ""seeincentivefirst_noconflict"": -0.12891022021063817, ""female"": 0.03791296758431605, ""age"": -0.00043111728520097727, ""stdalpha"": 0.07002651073412529}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""controls"": {""spec_id"": ""rc/controls/loo/incentiveB"", ""family"": ""loo"", ""dropped"": [""incentiveB""], ""n_controls"": 5}}",missingalpha==0,,TableC1-Col3 minus incentiveB,,1,
180741-V1,G2__rc__loo__female,rc/controls/loo/female,modules/robustness/controls.md#leave-one-out-controls-loo,G2,recommendincentive,seeincentivefirst,0.14609093619012514,0.06169664286477544,0.018541287570458698,0.024664452627354824,0.26751741975289545,299,0.12000220850510435,"{""coefficients"": {""Intercept"": 0.7069018949858227, ""seeincentivefirst"": 0.14609093619012514, ""noconflict"": 0.25845363279994404, ""seeincentivefirst_noconflict"": -0.1270066658398895, ""incentiveB"": -0.17022114917002315, ""age"": -3.212861651334615e-05, ""stdalpha"": 0.07476351833260962}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""controls"": {""spec_id"": ""rc/controls/loo/female"", ""family"": ""loo"", ""dropped"": [""female""], ""n_controls"": 5}}",missingalpha==0,,TableC1-Col3 minus female,,1,
180741-V1,G2__rc__loo__age,rc/controls/loo/age,modules/robustness/controls.md#leave-one-out-controls-loo,G2,recommendincentive,seeincentivefirst,0.14974979470373778,0.06123437200551735,0.015054929993252308,0.02923311631490988,0.2702664730925657,299,0.1234725784043772,"{""coefficients"": {""Intercept"": 0.6801477806152596, ""seeincentivefirst"": 0.14974979470373778, ""noconflict"": 0.2600896152860944, ""seeincentivefirst_noconflict"": -0.1296005261045205, ""incentiveB"": -0.17490537432556721, ""female"": 0.05128970268381599, ""stdalpha"": 0.07664657884574844}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""controls"": {""spec_id"": ""rc/controls/loo/age"", ""family"": ""loo"", ""dropped"": [""age""], ""n_controls"": 5}}",missingalpha==0,,TableC1-Col3 minus age,,1,
180741-V1,G2__rc__loo__stdalpha,rc/controls/loo/stdalpha,modules/robustness/controls.md#leave-one-out-controls-loo,G2,recommendincentive,seeincentivefirst,0.16862327172955624,0.06258219869842663,0.007459211934599974,0.04545390677347509,0.2917926366856374,299,0.09346404554851628,"{""coefficients"": {""Intercept"": 0.6917607636079323, ""seeincentivefirst"": 0.16862327172955624, ""noconflict"": 0.27836131139141346, ""seeincentivefirst_noconflict"": -0.14180747534473528, ""incentiveB"": -0.16344818527043745, ""female"": 0.04345617833647117, ""age"": -0.0007099835137642902}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""controls"": {""spec_id"": ""rc/controls/loo/stdalpha"", ""family"": ""loo"", ""dropped"": [""stdalpha""], ""n_controls"": 5}}",missingalpha==0,,TableC1-Col3 minus stdalpha,,1,
180741-V1,G2__rc__controls__minimal_nodemog,rc/controls/minimal_nodemog,modules/robustness/controls.md#minimal-controls,G2,recommendincentive,seeincentivefirst,0.16760865831001093,0.06164984952254126,0.006942936760344631,0.04627770471458262,0.28893961190543926,299,0.09093472825067317,"{""coefficients"": {""Intercept"": 0.6860613226233061, ""seeincentivefirst"": 0.16760865831001093, ""noconflict"": 0.27769424475359916, ""seeincentivefirst_noconflict"": -0.13959938716007325, ""incentiveB"": -0.15991906535107211}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""controls"": {""spec_id"": ""rc/controls/minimal_nodemog"", ""family"": ""minimal"", ""dropped"": [""female"", ""age"", ""stdalpha""], ""n_controls"": 3}}",missingalpha==0,,noconflict seeincentivefirst_noconflict incentiveB (no demographics),,1,
180741-V1,G2__rc__sample__include_inattentive,rc/sample/include_inattentive,modules/robustness/sample.md#include-inattentive,G2,recommendincentive,seeincentivefirst,0.17303311946153374,0.0596995355286712,0.004009679761376672,0.05557995633199768,0.2904862825910698,327,0.08836117467235782,"{""coefficients"": {""Intercept"": 0.7074111962966861, ""seeincentivefirst"": 0.17303311946153374, ""noconflict"": 0.20570758871046613, ""seeincentivefirst_noconflict"": -0.08208474639914688, ""incentiveB"": -0.18118396020297986, ""female"": 0.04483662845903027, ""age"": -0.0011512597145120866}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""sample"": {""spec_id"": ""rc/sample/include_inattentive"", ""description"": ""Include inattentive participants; stdalpha dropped since it is missing for inattentive""}}","All nochoice participants (including inattentive, no stdalpha)",,noconflict seeincentivefirst_noconflict incentiveB female age (no stdalpha - missing for inattentive),,1,
180741-V1,G2__rc__sample__restrict_conflict_only,rc/sample/restrict_conflict_only,modules/robustness/sample.md#restrict-subgroup,G2,recommendincentive,seeincentivefirst,0.14162137075152095,0.062496062779004165,0.024480471287961825,0.018410983453297572,0.26483175804974435,213,0.1373871707753842,"{""coefficients"": {""Intercept"": 0.6958219930906865, ""seeincentivefirst"": 0.14162137075152095, ""incentiveB"": -0.19285040191592223, ""female"": 0.0866847579612609, ""age"": -0.0005333186676174444, ""stdalpha"": 0.10837394495704195}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""sample"": {""spec_id"": ""rc/sample/restrict_conflict_only"", ""description"": ""Restrict to conflict subsample""}}",missingalpha==0 & conflict==1,,noconflict incentiveB female age stdalpha,,1,
180741-V1,G2__rc__sample__restrict_noconflict_only,rc/sample/restrict_noconflict_only,modules/robustness/sample.md#restrict-subgroup,G2,recommendincentive,seeincentivefirst,0.030255810442664743,0.08078860354309328,0.70901883996599,-0.13051863432267255,0.19103025520800201,86,0.027946670563552045,"{""coefficients"": {""Intercept"": 0.9345319226222156, ""seeincentivefirst"": 0.030255810442664743, ""incentiveB"": -0.06579607020899617, ""female"": -0.055456546960496664, ""age"": -5.9040249358827305e-05, ""stdalpha"": -0.025956770710932893}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""sample"": {""spec_id"": ""rc/sample/restrict_noconflict_only"", ""description"": ""Restrict to no-conflict subsample""}}",missingalpha==0 & conflict==0,,noconflict incentiveB female age stdalpha,,1,
180741-V1,G2__rc__sample__restrict_incentiveA_only,rc/sample/restrict_incentiveA_only,modules/robustness/sample.md#restrict-subgroup,G2,recommendincentive,seeincentivefirst,0.10801796529139945,0.07724059597089901,0.16409518586587524,-0.04463615091306486,0.26067208149586374,153,0.07695212050249822,"{""coefficients"": {""Intercept"": 0.6995489065063627, ""seeincentivefirst"": 0.10801796529139945, ""noconflict"": 0.22262642331507518, ""seeincentivefirst_noconflict"": -0.12069968010771912, ""female"": 0.06368253259840866, ""age"": 4.3249428115227993e-05, ""stdalpha"": 0.0677064167224876}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""sample"": {""spec_id"": ""rc/sample/restrict_incentiveA_only"", ""description"": ""Restrict to incentiveA observations""}}",missingalpha==0 & incentiveA==1,,noconflict seeincentivefirst_noconflict female age stdalpha,,1,
180741-V1,G2__rc__sample__restrict_incentiveB_only,rc/sample/restrict_incentiveB_only,modules/robustness/sample.md#restrict-subgroup,G2,recommendincentive,seeincentivefirst,0.20967865388369247,0.10631105190588301,0.05055858951816128,-0.000517189810244234,0.4198744975776292,146,0.13834153909880031,"{""coefficients"": {""Intercept"": 0.5293255761390229, ""seeincentivefirst"": 0.20967865388369247, ""noconflict"": 0.30797605661122496, ""seeincentivefirst_noconflict"": -0.18249740685572052, ""female"": 0.038515550491123936, ""age"": -0.0015168217584222105, ""stdalpha"": 0.08323940256951701}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""sample"": {""spec_id"": ""rc/sample/restrict_incentiveB_only"", ""description"": ""Restrict to incentiveB observations""}}",missingalpha==0 & incentiveB==1,,noconflict seeincentivefirst_noconflict female age stdalpha,,1,
180741-V1,G2__rc__outcome__probit,rc/outcome/probit,modules/robustness/functional_form.md#probit,G2,recommendincentive,seeincentivefirst,0.46424832611002986,0.19108952600784282,0.015120467593846328,0.08971973731182797,0.8387769149082318,299,0.11332079196275091,"{""coefficients"": {""Intercept"": 0.6232728735153722, ""seeincentivefirst"": 0.46424832611002986, ""noconflict"": 0.8500312413000936, ""seeincentivefirst_noconflict"": -0.3706744063896404, ""incentiveB"": -0.5963310917626966, ""female"": 0.18659197434806524, ""age"": -0.002319586552890225, ""stdalpha"": 0.26294757022457155}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""functional_form"": {""spec_id"": ""rc/outcome/probit"", ""model"": ""probit"", ""interpretation"": ""Probit coefficients (not marginal effects)""}}",missingalpha==0,,TableC1-Col3 controls,,1,
180741-V1,G2__rc__outcome__logit,rc/outcome/logit,modules/robustness/functional_form.md#logit,G2,recommendincentive,seeincentivefirst,0.7857528128989846,0.3256697011089607,0.015833576653226884,0.14745192786949746,1.4240536979284717,299,0.11457797502383171,"{""coefficients"": {""Intercept"": 1.019490108485332, ""seeincentivefirst"": 0.7857528128989846, ""noconflict"": 1.485604404874023, ""seeincentivefirst_noconflict"": -0.577811806984053, ""incentiveB"": -1.0265199035560586, ""female"": 0.3304288883371707, ""age"": -0.0035930454935309605, ""stdalpha"": 0.4524180604644302}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors randomly assigned to see incentive first (seeincentivefirst=1) or quality first (seeincentivefirst=0)"", ""experiment_type"": ""online_experiment"", ""platform"": ""MTurk/CloudResearch"", ""se_type"": ""HC3"", ""sample_restriction"": ""missingalpha==0 (attentive participants only), conflict==1 subsample for main test""}}, ""functional_form"": {""spec_id"": ""rc/outcome/logit"", ""model"": ""logit"", ""interpretation"": ""Logit coefficients (not marginal effects)""}}",missingalpha==0,,TableC1-Col3 controls,,1,
180741-V1,G3__rc__loo__professionalsfree,rc/controls/loo/professionalsfree,modules/robustness/controls.md#leave-one-out-controls-loo,G3,choicebefore,seeincentivecostly,-0.11637596835431566,0.016700791834769385,3.5578207047137766e-12,-0.14911563868787314,-0.08363629802075817,5908,0.032083272077397584,"{""coefficients"": {""Intercept"": 0.6478907954293193, ""seeincentivecostly"": -0.11637596835431566, ""seequalitycostly"": 0.16326956219302846, ""wave2"": 0.0608626224722945, ""wave3"": -0.07527458687679572, ""professionalscloudresearch"": -0.032167770528200836, ""incentiveshigh"": -0.061865622606980336, ""incentiveleft"": 0.06344040277753761, ""incentiveshigh_incentiveleft"": -0.005927468400800306, ""age"": -0.002523197316285297, ""female"": -0.030619633770568866}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/loo/professionalsfree"", ""family"": ""loo"", ""dropped"": [""professionalsfree""], ""n_controls"": 10}}",Highx10==0 & Highx100==0,,Table2-Col1 minus professionalsfree,,1,
180741-V1,G3__rc__loo__wave2,rc/controls/loo/wave2,modules/robustness/controls.md#leave-one-out-controls-loo,G3,choicebefore,seeincentivecostly,-0.14453568844930148,0.01711745252256299,0.0,-0.1780921663746353,-0.11097921052396767,5908,0.03414261624498849,"{""coefficients"": {""Intercept"": 0.6798176320024198, ""seeincentivecostly"": -0.14453568844930148, ""professionalsfree"": -0.10082031906514455, ""seequalitycostly"": 0.14913991464594525, ""wave3"": -0.0915856816382461, ""professionalscloudresearch"": 0.038430573567137, ""incentiveshigh"": -0.031312938913506595, ""incentiveleft"": 0.0939751025947503, ""incentiveshigh_incentiveleft"": -0.03651681119127295, ""age"": -0.0025860991796175085, ""female"": -0.029053062338074927}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/loo/wave2"", ""family"": ""loo"", ""dropped"": [""wave2""], ""n_controls"": 10}}",Highx10==0 & Highx100==0,,Table2-Col1 minus wave2,,1,
180741-V1,G3__rc__loo__wave3,rc/controls/loo/wave3,modules/robustness/controls.md#leave-one-out-controls-loo,G3,choicebefore,seeincentivecostly,-0.1391756579162904,0.017824331119711857,6.8833827526759706e-15,-0.1741178768571083,-0.10423343897547252,5908,0.03238417808387206,"{""coefficients"": {""Intercept"": 0.6653475842509179, ""seeincentivecostly"": -0.1391756579162904, ""professionalsfree"": -0.08280969420501064, ""seequalitycostly"": 0.07573037771487863, ""wave2"": 0.048380885119059545, ""professionalscloudresearch"": 0.03807947432117594, ""incentiveshigh"": -0.061798623990371775, ""incentiveleft"": 0.06360346482843472, ""incentiveshigh_incentiveleft"": -0.006249883897605841, ""age"": -0.0026472436690034005, ""female"": -0.03129122889191582}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/loo/wave3"", ""family"": ""loo"", ""dropped"": [""wave3""], ""n_controls"": 10}}",Highx10==0 & Highx100==0,,Table2-Col1 minus wave3,,1,
180741-V1,G3__rc__loo__professionalscloudresearch,rc/controls/loo/professionalscloudresearch,modules/robustness/controls.md#leave-one-out-controls-loo,G3,choicebefore,seeincentivecostly,-0.13934605442932732,0.01779410330057057,5.773159728050814e-15,-0.17422901577066255,-0.10446309308799209,5908,0.0341852598905692,"{""coefficients"": {""Intercept"": 0.6741584848503615, ""seeincentivecostly"": -0.13934605442932732, ""professionalsfree"": -0.08354075141275598, ""seequalitycostly"": 0.1517339017298249, ""wave2"": 0.03605284667846424, ""wave3"": -0.08852877375482708, ""incentiveshigh"": -0.061791796138675394, ""incentiveleft"": 0.06351628201014908, ""incentiveshigh_incentiveleft"": -0.00605372721843556, ""age"": -0.0025737394533254577, ""female"": -0.02983277146169043}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/loo/professionalscloudresearch"", ""family"": ""loo"", ""dropped"": [""professionalscloudresearch""], ""n_controls"": 10}}",Highx10==0 & Highx100==0,,Table2-Col1 minus professionalscloudresearch,,1,
180741-V1,G3__rc__loo__incentiveshigh,rc/controls/loo/incentiveshigh,modules/robustness/controls.md#leave-one-out-controls-loo,G3,choicebefore,seeincentivecostly,-0.13934473250070328,0.017794108897415017,5.773159728050814e-15,-0.17422770481390404,-0.10446176018750253,5908,0.03398847703949881,"{""coefficients"": {""Intercept"": 0.6742024071235933, ""seeincentivecostly"": -0.13934473250070328, ""professionalsfree"": -0.0952327324505227, ""seequalitycostly"": 0.1517438153845742, ""wave2"": 0.004073716252343956, ""wave3"": -0.08859956735569402, ""professionalscloudresearch"": 0.03846849412602525, ""incentiveleft"": 0.0955060315774578, ""incentiveshigh_incentiveleft"": -0.06782442854042477, ""age"": -0.0025885650712029608, ""female"": -0.02885283974665514}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/loo/incentiveshigh"", ""family"": ""loo"", ""dropped"": [""incentiveshigh""], ""n_controls"": 10}}",Highx10==0 & Highx100==0,,Table2-Col1 minus incentiveshigh,,1,
180741-V1,G3__rc__loo__incentiveleft,rc/controls/loo/incentiveleft,modules/robustness/controls.md#leave-one-out-controls-loo,G3,choicebefore,seeincentivecostly,-0.13933581415876414,0.017794088444477624,5.773159728050814e-15,-0.17421874637671467,-0.10445288194081362,5908,0.03398562590426646,"{""coefficients"": {""Intercept"": 0.6735914944230145, ""seeincentivecostly"": -0.13933581415876414, ""professionalsfree"": -0.09518507240230785, ""seequalitycostly"": 0.15175793014750016, ""wave2"": 0.06737194692989573, ""wave3"": -0.08860623545894675, ""professionalscloudresearch"": 0.03839308751465222, ""incentiveshigh"": -0.09308968834948773, ""incentiveshigh_incentiveleft"": 0.05747864877812654, ""age"": -0.002567856399580885, ""female"": -0.029178653052382996}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/loo/incentiveleft"", ""family"": ""loo"", ""dropped"": [""incentiveleft""], ""n_controls"": 10}}",Highx10==0 & Highx100==0,,Table2-Col1 minus incentiveleft,,1,
180741-V1,G3__rc__loo__incentiveshigh_incentiveleft,rc/controls/loo/incentiveshigh_incentiveleft,modules/robustness/controls.md#leave-one-out-controls-loo,G3,choicebefore,seeincentivecostly,-0.13934202916614,0.017794100218020577,5.773159728050814e-15,-0.17422498446454796,-0.10445907386773204,5908,0.034333812939424724,"{""coefficients"": {""Intercept"": 0.6739961144681319, ""seeincentivecostly"": -0.13934202916614, ""professionalsfree"": -0.09520481254589586, ""seequalitycostly"": 0.15174686590631195, ""wave2"": 0.03758013608267971, ""wave3"": -0.08859062932756494, ""professionalscloudresearch"": 0.03841438941605583, ""incentiveshigh"": -0.06472605844364358, ""incentiveleft"": 0.060412398189054854, ""age"": -0.0025794783385613947, ""female"": -0.02911302973870526}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/loo/incentiveshigh_incentiveleft"", ""family"": ""loo"", ""dropped"": [""incentiveshigh_incentiveleft""], ""n_controls"": 10}}",Highx10==0 & Highx100==0,,Table2-Col1 minus incentiveshigh_incentiveleft,,1,
180741-V1,G3__rc__loo__age,rc/controls/loo/age,modules/robustness/controls.md#leave-one-out-controls-loo,G3,choicebefore,seeincentivecostly,-0.13791596337379156,0.017811569868453996,1.1324274851176597e-14,-0.172833157088167,-0.10299876965941612,5915,0.03032704357735516,"{""coefficients"": {""Intercept"": 0.578284098096609, ""seeincentivecostly"": -0.13791596337379156, ""professionalsfree"": -0.09163413769822036, ""seequalitycostly"": 0.15468528956367045, ""wave2"": 0.037467668142912504, ""wave3"": -0.09411444925758283, ""professionalscloudresearch"": 0.035739270088261256, ""incentiveshigh"": -0.06389834453575509, ""incentiveleft"": 0.059987673398847904, ""incentiveshigh_incentiveleft"": -0.001640450702227872, ""female"": -0.03222811119450399}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/loo/age"", ""family"": ""loo"", ""dropped"": [""age""], ""n_controls"": 10}}",Highx10==0 & Highx100==0,,Table2-Col1 minus age,,1,
180741-V1,G3__rc__loo__female,rc/controls/loo/female,modules/robustness/controls.md#leave-one-out-controls-loo,G3,choicebefore,seeincentivecostly,-0.1390782244719864,0.017798672593119836,6.439293542825908e-15,-0.17397014330067914,-0.10418630564329365,5908,0.033502312320252914,"{""coefficients"": {""Intercept"": 0.6609932590297447, ""seeincentivecostly"": -0.1390782244719864, ""professionalsfree"": -0.09702921739237988, ""seequalitycostly"": 0.15245914789208034, ""wave2"": 0.035721799232182105, ""wave3"": -0.09141861103647653, ""professionalscloudresearch"": 0.043684704217276146, ""incentiveshigh"": -0.06043035936046964, ""incentiveleft"": 0.06387395108439471, ""incentiveshigh_incentiveleft"": -0.006083948132957796, ""age"": -0.0026413284992048737}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/loo/female"", ""family"": ""loo"", ""dropped"": [""female""], ""n_controls"": 10}}",Highx10==0 & Highx100==0,,Table2-Col1 minus female,,1,
180741-V1,G3__rc__add__stdalpha,rc/controls/add/stdalpha,modules/robustness/controls.md#add-controls,G3,choicebefore,seeincentivecostly,-0.1395211184214298,0.017761816210167005,4.884981308350689e-15,-0.17434176684749006,-0.10470046999536956,5196,0.03972589664899018,"{""coefficients"": {""Intercept"": 0.6616511363605048, ""seeincentivecostly"": -0.1395211184214298, ""seequalitycostly"": 0.15227284138285227, ""wave2"": 0.03465099817593242, ""wave3"": -0.08983775724511145, ""incentiveshigh"": -0.06097110825893654, ""incentiveleft"": 0.062394195084718676, ""incentiveshigh_incentiveleft"": -0.0051261043240801545, ""age"": -0.002316414282381311, ""female"": -0.023666952045536437, ""stdalpha"": 0.028194872745175566}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/add/stdalpha"", ""family"": ""add"", ""added"": [""stdalpha""], ""n_controls"": 12}}",Highx10==0 & Highx100==0,,Table2-Col1 plus stdalpha,,1,
180741-V1,G3__rc__add__selfishseeincentivecostly,rc/controls/add/selfishseeincentivecostly,modules/robustness/controls.md#add-controls,G3,choicebefore,seeincentivecostly,-0.13919915964980117,0.01779760686014468,6.217248937900877e-15,-0.17408997283970462,-0.10430834645989771,5196,0.03688822796365199,"{""coefficients"": {""Intercept"": 0.6671160677908603, ""seeincentivecostly"": -0.13919915964980117, ""seequalitycostly"": 0.15204963802472996, ""wave2"": 0.03608228403446093, ""wave3"": -0.08925198252555072, ""incentiveshigh"": -0.061724016095702286, ""incentiveleft"": 0.0633705248916077, ""incentiveshigh_incentiveleft"": -0.005694362224178516, ""age"": -0.0024413599479968626, ""female"": -0.025941510962650884, ""selfishseeincentivecostly"": 0.016619374380249716}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/add/selfishseeincentivecostly"", ""family"": ""add"", ""added"": [""selfishseeincentivecostly""], ""n_controls"": 12}}",Highx10==0 & Highx100==0,,Table2-Col1 plus selfishseeincentivecostly,,1,
180741-V1,G3__rc__add__selfishseequalitycostly,rc/controls/add/selfishseequalitycostly,modules/robustness/controls.md#add-controls,G3,choicebefore,seeincentivecostly,-0.13923135773857997,0.01779664601841689,6.217248937900877e-15,-0.17412028727359136,-0.1043424282035686,5196,0.03681233544662599,"{""coefficients"": {""Intercept"": 0.667298527896172, ""seeincentivecostly"": -0.13923135773857997, ""seequalitycostly"": 0.15220391870758992, ""wave2"": 0.03609817249345094, ""wave3"": -0.08913198716587695, ""incentiveshigh"": -0.06174517780752243, ""incentiveleft"": 0.06336467049891192, ""incentiveshigh_incentiveleft"": -0.005693241832479072, ""age"": -0.002440064619410359, ""female"": -0.026400883402112187, ""selfishseequalitycostly"": 0.017890068676431833}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""controls"": {""spec_id"": ""rc/controls/add/selfishseequalitycostly"", ""family"": ""add"", ""added"": [""selfishseequalitycostly""], ""n_controls"": 12}}",Highx10==0 & Highx100==0,,Table2-Col1 plus selfishseequalitycostly,,1,
180741-V1,G3__rc__sample__include_inattentive,rc/sample/include_inattentive,modules/robustness/sample.md#include-inattentive,G3,choicebefore,seeincentivecostly,-0.1359364279625888,0.016893613217270145,8.881784197001252e-16,-0.1690534351066689,-0.10281942081850873,6547,0.03609642498760646,"{""coefficients"": {""Intercept"": 0.6832560327323941, ""seeincentivecostly"": -0.1359364279625888, ""professionalsfree"": -0.1033384900221064, ""seequalitycostly"": 0.1540066600975518, ""wave2"": 0.06369646083271775, ""wave3"": -0.09966537653995255, ""professionalscloudresearch"": 0.03739756804811294, ""incentiveshigh"": -0.05981451175597136, ""incentiveleft"": 0.05079388584654373, ""incentiveshigh_incentiveleft"": -0.020036166207133867, ""age"": -0.0025232029452551107, ""female"": -0.03452696620786269}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""sample"": {""spec_id"": ""rc/sample/include_inattentive"", ""description"": ""Include inattentive participants""}}","Highx10==0 & Highx100==0, including inattentive",,Table2-Col1 controls,,1,
180741-V1,G3__rc__sample__include_high_stakes_10x,rc/sample/include_high_stakes_10x,modules/robustness/sample.md#include-subgroup,G3,choicebefore,seeincentivecostly,-0.14823069007563228,0.017275829009616474,0.0,-0.18209733523551686,-0.1143640449157477,6183,0.032878180167234206,"{""coefficients"": {""Intercept"": 0.6843957283775709, ""seeincentivecostly"": -0.14823069007563228, ""professionalsfree"": -0.09976941405418756, ""seequalitycostly"": 0.11553977403718663, ""wave2"": 0.031519021191471264, ""wave3"": -0.0566271179396257, ""professionalscloudresearch"": 0.038291886420178216, ""incentiveshigh"": -0.061705593995364155, ""incentiveleft"": 0.06370808736606341, ""incentiveshigh_incentiveleft"": -0.006428854248908777, ""age"": -0.0027184067624858236, ""female"": -0.030432165336913213}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""sample"": {""spec_id"": ""rc/sample/include_high_stakes_10x"", ""description"": ""Include 10x high-stakes participants""}}",Highx100==0 (includes 10x stakes),,Table2-Col1 controls,,1,
180741-V1,G3__rc__sample__include_high_stakes_100x,rc/sample/include_high_stakes_100x,modules/robustness/sample.md#include-subgroup,G3,choicebefore,seeincentivecostly,-0.15159209349624758,0.017170247195978115,0.0,-0.18525164586622184,-0.11793254112627333,6293,0.032337174111469746,"{""coefficients"": {""Intercept"": 0.6878458881836343, ""seeincentivecostly"": -0.15159209349624758, ""professionalsfree"": -0.101724731464214, ""seequalitycostly"": 0.10183942977236465, ""wave2"": 0.02975425756472341, ""wave3"": -0.04474115812486104, ""professionalscloudresearch"": 0.038815480361009756, ""incentiveshigh"": -0.06153014990810061, ""incentiveleft"": 0.06384251509821717, ""incentiveshigh_incentiveleft"": -0.0066276437197885915, ""age"": -0.002800428332013327, ""female"": -0.027887127840837213}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""sample"": {""spec_id"": ""rc/sample/include_high_stakes_100x"", ""description"": ""Include all high-stakes participants""}}",All stakes included,,Table2-Col1 controls,,1,
180741-V1,G3__rc__sample__restrict_nonprofessionals_only,rc/sample/restrict_nonprofessionals_only,modules/robustness/sample.md#restrict-subgroup,G3,choicebefore,seeincentivecostly,-0.13924442907348117,0.017794915972347655,5.995204332975845e-15,-0.1741299654181369,-0.10435889272882544,5196,0.036555503337744044,"{""coefficients"": {""Intercept"": 0.6681224905063072, ""seeincentivecostly"": -0.13924442907348117, ""seequalitycostly"": 0.15194856561898837, ""wave2"": 0.03608655031224001, ""wave3"": -0.08908513353740977, ""incentiveshigh"": -0.06173197913648505, ""incentiveleft"": 0.06339246681664099, ""incentiveshigh_incentiveleft"": -0.005747211303099672, ""age"": -0.002460910787328708, ""female"": -0.02646954054742144}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""sample"": {""spec_id"": ""rc/sample/restrict_nonprofessionals_only"", ""description"": ""Restrict to non-professionals only""}}",Highx10==0 & Highx100==0 & professionals==0,,Table2-Col1 controls,,1,
180741-V1,G3__rc__outcome__probit,rc/outcome/probit,modules/robustness/functional_form.md#probit,G3,choicebefore,seeincentivecostly,-0.35451232400989646,0.045610252074991316,7.686358758936107e-15,-0.4439067754026727,-0.2651178726171202,5908,0.025114360383316714,"{""coefficients"": {""Intercept"": 0.44723356282143023, ""seeincentivecostly"": -0.35451232400989646, ""professionalsfree"": -0.24130833962370363, ""seequalitycostly"": 0.39179284125871155, ""wave2"": 0.0918415432655121, ""wave3"": -0.22970083121921347, ""professionalscloudresearch"": 0.09645263742378984, ""incentiveshigh"": -0.15822275608966008, ""incentiveleft"": 0.16980030618239023, ""incentiveshigh_incentiveleft"": -0.022671958734285555, ""age"": -0.006675410764871453, ""female"": -0.07494950171240317}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""functional_form"": {""spec_id"": ""rc/outcome/probit"", ""model"": ""probit"", ""interpretation"": ""Probit coefficients (not marginal effects)""}}",Highx10==0 & Highx100==0,,Table2-Col1 controls,,1,
180741-V1,G3__rc__outcome__logit,rc/outcome/logit,modules/robustness/functional_form.md#logit,G3,choicebefore,seeincentivecostly,-0.5676893155669591,0.07328481689212923,9.457695190274604e-15,-0.7113249172891449,-0.42405371384477325,5908,0.02510842974176475,"{""coefficients"": {""Intercept"": 0.7174840057775597, ""seeincentivecostly"": -0.5676893155669591, ""professionalsfree"": -0.3860697746435141, ""seequalitycostly"": 0.631010814724927, ""wave2"": 0.14727435181521922, ""wave3"": -0.36980005151532686, ""professionalscloudresearch"": 0.15395008978798616, ""incentiveshigh"": -0.25356709968533275, ""incentiveleft"": 0.27334319649155564, ""incentiveshigh_incentiveleft"": -0.03812219251966849, ""age"": -0.010717035224771665, ""female"": -0.12065699748632626}, ""inference"": {""spec_id"": ""infer/se/hc/hc3"", ""params"": {}}, ""software"": {""runner_language"": ""python"", ""runner_version"": ""3.12.7"", ""packages"": {""pyfixest"": ""0.40.1"", ""pandas"": ""2.2.3"", ""numpy"": ""2.1.3"", ""statsmodels"": ""0.14.6""}}, ""surface_hash"": ""sha256:88127ca900cb350b3283f8dbc75687c63056c6b4d59af1dc7ab92f2023cab56d"", ""design"": {""randomized_experiment"": {""estimator"": ""ols_lpm"", ""randomization_unit"": ""individual"", ""randomization_scheme"": ""Advisors choose preferred order then are randomly assigned (getbefore). Outcome is preference itself (choicebefore) as a function of treatment condition indicators."", ""experiment_type"": ""online_experiment"", ""platform"": ""CloudResearch/Prolific/MTurk"", ""se_type"": ""HC3"", ""sample_restriction"": ""Highx10==0 & Highx100==0 (baseline stakes only), professionals excluded from some specs""}}, ""functional_form"": {""spec_id"": ""rc/outcome/logit"", ""model"": ""logit"", ""interpretation"": ""Logit coefficients (not marginal effects)""}}",Highx10==0 & Highx100==0,,Table2-Col1 controls,,1,
